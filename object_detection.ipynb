{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### %%writefile test\n",
    "## Midterm\n",
    "<b>The general objective is to detect blue cursor, yellow timer, and human skin from input video. Your output should be similar to midterm_demo.mp4. Please complete steps 1-10 in one single code cell, steps 11-12 in another markdown cell, and upload your Jupyter notebook file (*.ipynb). The whole process can be divided to the following steps:</b>\n",
    "1. (5pts) Input images from video file WiiPlay.mp4 with the same level number as the last two digits of your student id, and show the images in the \"input\" window.\n",
    "2. (5pts) Use <i>cv2.cvtColor()</i> to convert images from BGR to HSV format.\n",
    "3. (10pts) Use <i>cv2.createTrackbar()</i> to create six trackbars (HueMin, HueMax, SatMin SatMax, ValMin, ValMax), and use <i>cv2.getTrackbarPos()</i> to get the current value of each trackbar.\n",
    "4. (10pts) Use <i>cv2.threshold()</i> or <i>cv2.inRange()</i> to apply double thresholding to each channel (Hue, Sat, Val) based on current values of the six trackbars\n",
    "5. (10pts) Apply morphological filters to remove noise (outliers & holes), and show the detected regions in the \"test\" window..\n",
    "6. (10pts) Find out the best color range to detect <b>blue cursor</b>, apply these thresholds, and show the detected regions in the \"cursor\" window.\n",
    "7. (10pts) Find out the best color range to detect <b>yellow timer</b>, apply these thresholds, and show the detected regions in the \"timer\" window.\n",
    "8. (10pts) Find out the best color range to detect <b>human skin</b>, apply these thresholds, and show the detected regions in the \"skin\" window.\n",
    "9. (10pts) Use <i>cv2.connectedComponents()</i> and <i>cv2.putText()</i> to count and display how many skin regions in each frame.\n",
    "10. (10pts) Show each individual skin region using different color.\n",
    "11. (5pts) Any comments regarding the midterm? Which steps you believe you have completed? Which steps bother you?\n",
    "12. (5pts) Any comments regarding the classes up to now? pace too fast or slow? quiz too hard or simple? prefer C or Python?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def hMaxCallback(pos):\n",
    "    pass\n",
    "def hMinCallback(pos):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('Test')\n",
    "cv2.createTrackbar('HueMin', 'Test',   0, 180, hMinCallback)\n",
    "cv2.createTrackbar('HueMax', 'Test',  49, 180, hMaxCallback)\n",
    "cv2.createTrackbar('SatMin', 'Test',  33, 255, hMinCallback)\n",
    "cv2.createTrackbar('SatMax', 'Test', 161, 255, hMaxCallback)\n",
    "cv2.createTrackbar('ValMin', 'Test',  25, 255, hMinCallback)\n",
    "cv2.createTrackbar('ValMax', 'Test', 162, 255, hMaxCallback)\n",
    "\n",
    "cv2.namedWindow('Cursor')\n",
    "cv2.namedWindow('Timer')\n",
    "cv2.namedWindow('Skin')\n",
    "cv2.namedWindow('Connect and Display')\n",
    "\n",
    "out_size = (480, 270)\n",
    "cap = cv2.VideoCapture('WiiPlay.mp4')\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open the video file\")\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES , 410)\n",
    "\n",
    "cnt = 0\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "\n",
    "while (True): \n",
    "    ret, frame = cap.read()\n",
    "    cnt += 1\n",
    "    if ret == False:\n",
    "        break\n",
    "    cur_frame = cv2.resize(frame, out_size, 0, 0, interpolation=cv2.INTER_AREA)\n",
    "    cv2.imshow('Input', cur_frame)\n",
    "    \n",
    "    hMax = cv2.getTrackbarPos('HueMax','Test')\n",
    "    hMin = cv2.getTrackbarPos('HueMin','Test')\n",
    "    sMax = cv2.getTrackbarPos('SatMax','Test')\n",
    "    sMin = cv2.getTrackbarPos('SatMin','Test')\n",
    "    vMax = cv2.getTrackbarPos('ValMax','Test')\n",
    "    vMin = cv2.getTrackbarPos('ValMin','Test')\n",
    "    \n",
    "    cur_frame = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_color = np.array([hMin, sMin, vMin])\n",
    "    upper_color = np.array([hMax, sMax, vMax])\n",
    "    mask = cv2.inRange(cur_frame, lower_color, upper_color)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.erode(mask, kernel, iterations=5)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=5)\n",
    "    cv2.imshow('Test', mask)\n",
    "    \n",
    "    cursor = cv2.inRange(cur_frame, np.array([100, 43, 46]), np.array([124, 255, 255]))\n",
    "    cv2.imshow('Cursor', cursor)\n",
    "    timer = cv2.inRange(cur_frame, np.array([0, 163, 171]), np.array([31, 255, 255]))\n",
    "    cv2.imshow('Timer', timer)\n",
    "    skin = cv2.inRange(cur_frame, np.array([0, 33, 25]), np.array([49, 161, 162]))\n",
    "    skin = cv2.morphologyEx(skin, cv2.MORPH_OPEN, kernel)\n",
    "    skin = cv2.morphologyEx(skin, cv2.MORPH_CLOSE, kernel)\n",
    "    skin = cv2.erode(skin, kernel, iterations=5)\n",
    "    skin = cv2.dilate(skin, kernel, iterations=5)\n",
    "    cv2.imshow('Skin', skin)\n",
    "    \n",
    "    num_objects, labels = cv2.connectedComponents(skin)\n",
    "    output = np.zeros((skin.shape[0], skin.shape[1], 3), np.uint8)\n",
    "    for i in range(1, num_objects):\n",
    "        mask = labels == i\n",
    "        output[:, :, 0][mask] = np.random.randint(0, 255)\n",
    "        output[:, :, 1][mask] = np.random.randint(0, 255)\n",
    "        output[:, :, 2][mask] = np.random.randint(0, 255)\n",
    "    output = cv2.putText(output, str(num_objects), (10, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.imshow('Connect and Display', output)\n",
    "\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 32:\n",
    "        cv2.waitKey()\n",
    "    if c == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. (5pts) Any comments regarding the midterm? Which steps you believe you have completed? Which steps bother you?\n",
    "\n",
    "      覺得期中考的題目出得非常詳盡，而且還附上結果影片跟程式碼範例非常有幫助。影片讓我可以更清楚的知道需要呈現出什麼樣的結果，盡力達成影片所呈現的效果；程式碼則給了我解題的方向，讓我可以知道該從何處下手，且更有架構。\n",
    "      \n",
    "      在所有的步驟中我想我在 1、2、3、4、6、7、9 的步驟有確實完成，而剩下的步驟則不能確定是否有達成需求。\n",
    "      \n",
    "      最困擾我的步驟是 8 跟 9，皮膚的顏色非常難抓，且還需要做侵蝕及擴張的動作，否則同一個人會被判定成兩個區塊，也常常會抓到一些相近顏色的非人物體，或是總有一些小點點無法排除，令我很困擾。\n",
    "\n",
    "\n",
    "12. (5pts) Any comments regarding the classes up to now? pace too fast or slow? quiz too hard or simple? prefer C or Python?\n",
    "\n",
    "      我認為現在的上課步調很舒服，可以扎實的學到理論知識又可以練習到實作的部分，練習的難度也很剛好，有挑戰性又不至於無法完成。\n",
    "      \n",
    "      比起 C 語言我更喜歡 Python，因為 Python 的套件非常豐富，而且語法也較直覺、簡易，很容易就可以實作出東西讓人很有成就感。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
